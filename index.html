<!DOCTYPE html>
<html>
  <head>
    <title>Tien V Nguyen</title>
    <link rel="stylesheet" href="style/navstyle.css">
    <link rel="stylesheet" href="style/textstyle.css">
    <link rel="stylesheet" href="style/style.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  </head>
  <body>
        <div id="navbar">
            <a href="#About">About</a>
            <a href="#Projects">Projects</a>
            <a href="#Contact">Contact</a>
        </div>
        <div id="About">
            <div class="bg-image"></div>
            <div class="bg-text">
                <h1>Tien Van Nguyen</h1>
                <p>A postgraduate research student in Electrical and Electronics Engineering, having two years of working and research experience in embedded software engineering, robotics, digital signal processing, and machine learning. I am committed to continuous learning and thrive on the opportunity to grow, as witnessing my own progress remains a primary driving force in my life.</p>
                <a href="../files/TienVNguyenCV.pdf" download="tienvannguyen_cv.pdf"><button class="downloadbtn"><i class="fa fa-download"></i> Download CV</button></a>
            </div>
        </div>
        <div class="main">
            <!-- EDUCATION -->
            <div class="cvsection">
                <h2>Education</h2>
                <!-- UCC -->
                <h3>University College Cork</h3>
                <p style="text-align:left;">
                    Cork, Ireland
                    <span style="float:right;">
                        May 2022 ‑ Current
                    </span>
                </p>
                <h4>MSc ‑ Electrical and Electronics Engineering</h4>
                <!-- TUM -->
                <h3>Technical University of Munich</h3>
                <p style="text-align:left;">
                    Munich, Germany
                    <span style="float:right;">
                        Oct 2019 ‑ Apr 2020
                    </span>
                </p>
                <h4>Exchange Student</h4>
                <!-- HUST -->
                <h3>Hanoi University of Science and Technology</h3>
                <p style="text-align:left;">
                    Hanoi, Vietnam
                    <span style="float:right;">
                        Oct 2015 ‑ Aug 2020
                    </span>
                </p>
                <h4>Engineer ‑ Control Engineering and Automation</h4>
            </div>
            <!-- EXPERIENCE -->
            <div class="cvsection">
                <h2>Work Experience</h2>
                <!-- VKIST -->
                <h3>Vietnam – Korea Institute of Science and Technology</h3>
                <p style="text-align:left;">
                    Hanoi, Vietnam
                    <span style="float:right;">
                        Aug 2021 ‑ Apr 2022
                    </span>
                </p>
                <h4>Research Engineer</h4>
                <!-- VIETTELTECH -->
                <!-- VKIST -->
                <h3>Viettel High Technology Industries Corporation</h3>
                <p style="text-align:left;">
                    Hanoi, Vietnam
                    <span style="float:right;">
                        Nov 2020 ‑ Aug 2021
                    </span>
                </p>
                <h4>Embedded Software Engineer</h4>
            </div>
            <div class="cvsection" id="Projects">
                <h2>Projects</h2>
                <h3 class="collapsible">Omnidirectional Robot Prototype Development</h3>
                <div id="project1">
                    <h4>DESCRIPTION</h4>
                    <p>Developing an omnidirectional robot prototype for research and development of a navigation system for field robots.</p>
                    <h4>CONTRIBUTIONS</h4>
                    <p>I designed the electrical system, safety management system, actuator control software, and graphical user interface.</p>
                    <ol>
                        <b><li>Actuator Control Software</li></b>
                        <div class="video-container">
                          <div class="video-box">
                            <p>I designed and developed a software to control BLDC motor drivers, which control the robot wheels. Control and query commands are sent to motor driver via an UART communication port. The main language used was C/C++ with Robot Operating System (ROS).<br>Source code: <a href="https://github.com/tiennvhust/bldc_driver">here</a></p>
                          </div>
                          <div class="video-box">
                            <video controls>
                              <source src="../videos/1683561766185.MP4" type="video/mp4">
                              Your browser does not support the video tag.
                            </video>
                          </div>
                        </div>
                        <b><li>Graphical User Interface</li></b>
                        <div class="video-container">
                          <div class="video-box">
                            <p>I designed and developed robot Graphical User Interface (GUI) using Qt Creator software. This GUI allows users to control the movement of the robot via a software joystick, displays robot's data and status. The main language used was C/C++ with Qt Creator and Robot Operating System (ROS).<br>Source code: <a href="https://github.com/tiennvhust/vk_omni_gui">here</a></p>
                          </div>
                          <div class="video-box">
                            <video controls>
                              <source src="https://user-images.githubusercontent.com/95061513/160900081-84f24e7f-518d-42c9-aed3-01580d267aa2.mp4" type="video/mp4">
                              Your browser does not support the video tag.
                            </video>
                          </div>
                        </div>
                        <b><li>Safety Management System</li></b>
                        <p>I designed a safety mechanism using a PLC and software to control the operation of the robot. The development of this system involving PLC programing and C/C++ with ROS.<br>Source code: <a href="https://github.com/tiennvhust/vk_omni_plc">here</a></p>
                    </ol>
                  </div>
                  <!-- Project 2 -->
                  <h3 class="collapsible">Real-time, AI-assisted Sonification Algorithm for Neonatal EEG</h3>
                  <div id="project2">
                    <h4>DESCRIPTION</h4>
                    <p>
                      This study presents a real-time processing design of the AI-assisted EEG sonification algorithm in [16] and its implementation on an ultra-low power microcontroller. Two patient-independent seizure detection neural networks were evaluated for their performance and power consumption on the microcontroller’s dedicated neural network accelerator. The real-time design allows for continuous availability of audio, saving time and effort for medical staff and enabling seizure detection as early as it occurs. The ultra-low power application can be used in clinical settings, such as Neonatal Intensive Care Units, for continuous EEG analysis. It is suitable for wearable devices.
                    </p>
                    <p>
                      The original algorithm had been re-designed in architecture along with some of its parts to process real-time data. The new architecture also needs to be high-speed and memory efficient, suitable for running on a resource-constrained platform. Taking advantage of a multithreading design, this architecture enables the processor to perform all digital signal processing tasks concurrently while retrieving the classification outputs of the seizure detection algorithm.
                    </p>
                    <ol>
                        <b><li>Original AI-assited Sonification Algorithm</li></b>
                        <div class="video-container">
                          <div class="video-box">
                            <p>A novel method of AI-driven spatial neonatal EEG sonification has been presented in [1]. It utilizes the Phase Vocoder (PV) algorithm with an AI-guided time-compression factor as an attention mechanism. The AI probabilities are used to modulate the audio playback speed, maintaining focus on the EEG regions with a high probability of seizures, while allowing quick audio rendering over non-seizure EEG segments. This method combines the accuracy and speed of AI algorithms with the interpretability and intuitiveness of sonification, it enables a quick, accurate, and interpretable seizure detection method while requiring little to no training from medical workers.</p>
                          </div>
                          <div class="video-box">
                            <img src="../images/original.gif" style="width:400px;">
                          </div>
                        </div>
                        <b><li>Real-Time Adaptation</li></b>
                        <div class="video-container">
                          <div class="video-box">
                            <p>This study presents a real-time adaptation of the AI-assisted EEG sonification algorithm and its implementation on an ultra-low power embedded system. A significant advantage of a real-time implementation is that the output audio is always available for listening. Medical workers can have access to real-time audio at any time without having to periodically restart the sonification algorithm, enabling seizure detection as soon as they occur. This ultra-low-power implementation is suitable for wearable devices, which can be widely adopted in clinical settings, including Intensive Care Units, for continuous neonatal EEG monitoring.</p>
                          </div>
                          <div class="video-box">
                            <img src="../images/realtime.gif" style="width:400px;">
                          </div>
                        </div>
                    </ol>
                    <h4>Listen to EEG</h4>
                    <p>The real-time (online) algorithm implemented with C/C++ is validated against the original design which implemented on Matlab. This website provideds a more interactive comparision between the two algorithm designs: <a href="https://tiennvhust.github.io/listen2eeg.github.io">Listen to EEG</a></p>
                    <h4>Neural Networks Quantization and Validation</h4>
                    <p>Two patient-independent seizure detection neural networks were implemented in this low-power application and compared in performance: A Fully Convolutional Neural Network (FCNN) contains three feature extraction blocks and a fully convolutional classification block, referred to as the VGGNet in this study [3]; and an improved Residual Network (ResNet) with total of 13 convolution layers in 4 feature extraction blocks [4].</p>
                    <p>Table I summarizes the performances of the ResNet and the VGGNet in both floating-point and integer formats. The ResNet model outperforms the VGGNet model in both floating-point and 8bit integers representations by 2.6% and 3% respectively.</p>
                    <table style="text-align: center;">
                      <caption>TABLE I. 	NEURAL NETWORKS PERFORMANCES</caption>
                      <tr>
                        <th>Model</th>
                        <th>Number of Parameters</th>
                        <th>Size (bytes)</th>
                        <th>AUC (%)</th>
                        <th>MAX78002 Inference Time (us)</th>
                      </tr>
                      <tr>
                        <td>ResNet 32b</td>
                        <td>45,090</td>
                        <td>180,360</td>
                        <td>98.0</td>
                        <td>-</td>
                      </tr>
                      <tr>
                        <td>ResNet 8b</td>
                        <td>45,090</td>
                        <td>45,090</td>
                        <td>97.6</td>
                        <td>937</td>
                      </tr>
                      <tr>
                        <td>VGG 32b</td>
                        <td>25,538</td>
                        <td>102,152</td>
                        <td>95.4</td>
                        <td>-</td>
                      </tr>
                      <tr>
                        <td>VGG 8b</td>
                        <td>25,538</td>
                        <td>25,538</td>
                        <td>94.6</td>
                        <td>248</td>
                      </tr>
                    </table>
                    <h4>Implementation Results</h4>
                    <p>The Real-time AI-assited Algorithm was implemented on <a href="https://www.analog.com/en/products/max78002.html">MAX78002</a>, a new breed of AI microcontrollers designed for running neural networks with ultra-low power consumption. It features an Arm Cortex-M4 with FPU CPU and an ultra-low-power deep neural network accelerator.</p>
                    <p>The power consumptions of two neural networks on the MAX78002 were measured by tracking the input current of net VCOREA which drives the CNN core on the MAX78002. The voltage drop at jumper JP4 with a preinstalled 10mΩ shunt resister on the development kit was measured using a 500x amplifier and an oscilloscope. Fig 3 shows the current values derived from the measured voltage drop. With VCOREA is 1.1V, the total energy was also calculated.</p>
                    <p>While Fig 3a1 and b1 detail the power signatures of two models in the sonification algorithm processing 8 channels EEG, a2 and b2 detail the power signatures processing a single input image. Three separated events marked in the figures are: CNN clock enabled, CNN starts, and CNN clock disabled. These events divide the total CNN operation period into two stages A and B. During stage A, first the accelerator is brought into a consistent state, next, kernels (weights) and biases are loaded, and finally the neural network’s architecture is configured. Stage B is when the input data being loaded, inference (peak), and output data being unloaded.</p>
                    <img src="images/energy.png" alt="energy" style="width: 80%; margin-top: 15px;">
                    <p style="text-align: center;">Fig. 3.	Neural Networks’ Power Signatures on MAX78002</p>
                    <h4>REFERENCES</h4>
                    <p>[1]&nbsp;S. Gomez-Quintana, A. O’Shea, A. Factor, E. Popovici, and A. Temko, “A method for AI assisted human interpretation of neonatal EEG,” Sci Rep, vol. 12, no. 1, p. 10932, 2022, doi: 10.1038/s41598-022-14894-4.
                      <br>[2]&nbsp;N. Stevenson, K. Tapani, L. Lauronen, and S. Vanhatalo, “A dataset of neonatal EEG recordings with seizures annotations,” Jun. 2018, doi: 10.5281/ZENODO.2547147.
                      <br>[3]&nbsp;A. O’Shea, G. Lightbody, G. Boylan, and A. Temko, “Neonatal seizure detection from raw multi-channel EEG using a fully convolutional architecture,” Neural Networks, vol. 123, 2020, doi: 10.1016/j.neunet.2019.11.023.
                      <br>[4]&nbsp;A. Daly, A. O’Shea, G. Lightbody, and A. Temko, “Towards Deeper Neural Networks for Neonatal Seizure Detection,” in 2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC), 2021, pp. 920–923. doi: 10.1109/EMBC46164.2021.9629485.
                    </p>
                  </div>
            </div>
            <div class="cvsection">
                <h2>Publications</h2>
                <p><span style="font-weight: bold;">T. Van Nguyen</span>, A. Daly, F. O’Sullivan, S. G. Quintana, A. Temko and E. Popovici, "A real-time and ultra-low power implementation of an AI-assisted sonification algorithm for neonatal EEG," 2023 9th International Workshop on Advances in Sensors and Interfaces (IWASI), Monopoli (Bari), Italy, 2023, pp. 313-318, doi: <a href="https://doi.org/10.1109/IWASI58316.2023.10164463" style="color: blue; text-decoration: underline;">10.1109/IWASI58316.2023.10164463</a>.</p>
            </div>
        </div>
        <!-- <div class="background"> -->
          <div class="contact" id="Contact">
            <div class="contact-container">
                  <div class="contact-box">
                      <i class="fa fa-envelope" style="font-size:36px;color: #333;"></i>
                      <p>nguyentien97.hust@gmail.com</p>
                  </div>
                  <div class="contact-box">
                      <i class="fa fa-phone-square" style="font-size:36px;color: #333;"></i>
                      <p>(+353)852593652</p>
                  </div>
                  <div class="contact-box">
                      <i class="fa fa-linkedin-square" style="font-size:36px;color:#0A66C2;"></i>
                      <p><a href="https://www.linkedin.com/in/tien-nguyen2807">tien-nguyen2807</a></p>
                  </div>
                  <div class="contact-box">
                    <i class="fa fa-github" style="font-size:36px;color:black;"></i>
                    <p><a href="https://github.com/tiennvhust">tiennvhust</a></p>
                </div>
            </div>
        </div>
        <!-- </div> -->
        <script src="scripts/script.js"></script>
        <script src="scripts/navscript.js"></script>
  </body>
</html>